actual_exclusion_IDs1 <- res[[1]]
updated_inclusion_IDs1 <- res[[2]]
length(actual_exclusion_IDs1) #0
length(updated_inclusion_IDs1) #10503
length(updated_inclusion_IDs1) #10502
#Exclude 2- Baseline eGFR <15
ExclusionID2 <- Baseline_EGFR_df[which(Baseline_EGFR_df[,"Baseline_eGFR"] < 15),"STUDY_PATIENT_ID"]
res <- exclude_pts_func(updated_inclusion_IDs1,ExclusionID2)
actual_exclusion_IDs2 <- res[[1]]
updated_inclusion_IDs2 <- res[[2]]
length(actual_exclusion_IDs2) #222
length(updated_inclusion_IDs2) #10281
length(updated_inclusion_IDs2) #10280
#Exclude 3- Kidney transplant before or during hospitalization
ExclusionID3 <- KidneyTransplant_df[which(KidneyTransplant_df[,"KidneyTrans_BEFOREorDURING"] == 1),"STUDY_PATIENT_ID"]
res <- exclude_pts_func(updated_inclusion_IDs2,ExclusionID3)
actual_exclusion_IDs3 <- res[[1]]
updated_inclusion_IDs3 <- res[[2]]
length(actual_exclusion_IDs3) #12
length(updated_inclusion_IDs3) #  10269
#Exclude 4- <1 SCr measurement in the first 3 days of ICU admission (D0 to D3)
ExclusionID4 <- Src_df[which(Src_df[,"NUM_SCr_inICU_D0_D3"] < 1),"STUDY_PATIENT_ID"]
res <- exclude_pts_func(updated_inclusion_IDs3,ExclusionID4)
actual_exclusion_IDs4 <- res[[1]]
updated_inclusion_IDs4 <- res[[2]]
length(actual_exclusion_IDs4) #215
length(updated_inclusion_IDs4) #10054
#Exclude 5- No AKI in the first 3 days of ICU admission (D0 to D3)
ExclusionID5 <- KDIGO_df[which(KDIGO_df[,"MAX_KDIGO_ICU_D0toD3"] == 0 |is.na(KDIGO_df[,"MAX_KDIGO_ICU_D0toD3"])==T),"STUDY_PATIENT_ID"]
res <- exclude_pts_func(updated_inclusion_IDs4,ExclusionID5)
actual_exclusion_IDs5 <- res[[1]]
updated_inclusion_IDs5 <- res[[2]]
length(actual_exclusion_IDs5) #7515
length(updated_inclusion_IDs5) # 2539
#Exclude 6- <24 hours of ICU stay
ExclusionID6 <- All_time_df[which(All_time_df[,"ICU_LOS_Hours"] < 24),"STUDY_PATIENT_ID"]
res <- exclude_pts_func(updated_inclusion_IDs5,ExclusionID6)
actual_exclusion_IDs6 <- res[[1]]
updated_inclusion_IDs6 <- res[[2]]
length(actual_exclusion_IDs6) #0
length(updated_inclusion_IDs6) # 2539
#Exclude 7- Died in the first 3 days (D0 to D3) of ICU admission
ExclusionID7 <- All_Mortality_df[which(All_Mortality_df[,"Death_ICU_D0toD3"] == 1),"STUDY_PATIENT_ID"]
res <- exclude_pts_func(updated_inclusion_IDs6,ExclusionID7)
actual_exclusion_IDs7 <- res[[1]]
updated_inclusion_IDs7 <- res[[2]]
length(actual_exclusion_IDs7) # 91
length(updated_inclusion_IDs7) # 2448
#Exclude 8 - ESRD (ESKD) diagnosis before hospitalization
ExclusionID8 <- Final_ESRD_BEFORE_AT_df[which(Final_ESRD_BEFORE_AT_df[,"ESRD_BEFORE_AT"] == 1),"STUDY_PATIENT_ID"]
res <- exclude_pts_func(updated_inclusion_IDs7,ExclusionID8)
actual_exclusion_IDs8 <- res[[1]]
updated_inclusion_IDs8 <- res[[2]]
length(actual_exclusion_IDs8) # 195
length(updated_inclusion_IDs8) #2233
#analysis ID before exlusion of ESRD before and at
Final_Anlaysis_ID <-as.data.frame(updated_inclusion_IDs8)
colnames(Final_Anlaysis_ID) <- "STUDY_PATIENT_ID"
nrow(Final_Anlaysis_ID) #2233
write.csv(Final_Anlaysis_ID,paste0(outdir,"Final_Analysis_ID.csv"),row.names = F)
Final_ID_df <- exclusionFeature_df[-which(exclusionFeature_df$Time_Exclusion == 1),] #-108
exclusion1<- which(0 < Final_ID_df$AGE < 18) #0
exclusion1<- which(Final_ID_df$AGE < 18 & Final_ID_df$AGE > 0) #0
length(exclusion1)
setwd("~/Desktop/DrChen_Projects/All_AKI_Projects/Other_Project/TAKI_Project/TAKI_Code/Process_UTSW")
setwd("~/Desktop/DrChen_Projects/All_AKI_Projects/Other_Project/TAKI_Project/TAKI_Code")
#######################################################################################
######                           Mortality Prediction   5                  ############
#feature file: Selected features2
#Outcome file: All_outcome.csv
#######################################################################################
#1.Selected features
feature_file <- c("All_Feature_imputed_normed.csv")
selected_features <- c("UrineOutput_D0toD3" , "Vasopressor_ICUD0toD3","FI02_D1_HIGH","Platelets_D1_LOW","AGE",
"BUN_D0toD3_HIGH","HR_D1_HIGH","LAST_KDIGO_ICU_D0toD3","PH_D1_LOW","Bilirubin_D1_HIGH",
"MAX_KDIGO_ICU_D0toD3","ECMO_ICUD0toD3","Hours_inICUD0toD3", "Temperature_D1_LOW", "Temperature_D1_HIGH")
#Outdir for mortality
outdir1 <- paste0(out_dir,"mortality/SelectedClinicalFeature2/")
#Outcome column name
outcome_colname <- "Death_inHOSP"
source("TAKI_Ultility.R")
library(rms)
library(PredictABEL)
library(pROC) #can also use this one for delong's methods
library(Rmisc)
library(caret)
#this script do 10 folds CV on UK data
#1. for each fold , down sampling 10 time, each instance get 10 predicted results
#2. compute confidence interval for performance metrics for each fold with each sampling index
#Data dir
data_dir <- "/Volumes/LJL_ExtPro/Data/AKI_Data/TAKI_Data_Extracted/uky/Model_Feature_Outcome/"
#out dir
out_dir <- "/Users/lucasliu/Desktop/DrChen_Projects/All_AKI_Projects/Other_Project/TAKI_Project/Intermediate_Results/Prediction_results0708/CV_performance/"
#feature file and outcome file names
outcome_file <- "All_outcome.csv"
#######################################################################################
######                           Mortality Prediction   5                  ############
#feature file: Selected features2
#Outcome file: All_outcome.csv
#######################################################################################
#1.Selected features
feature_file <- c("All_Feature_imputed_normed.csv")
selected_features <- c("UrineOutput_D0toD3" , "Vasopressor_ICUD0toD3","FI02_D1_HIGH","Platelets_D1_LOW","AGE",
"BUN_D0toD3_HIGH","HR_D1_HIGH","LAST_KDIGO_ICU_D0toD3","PH_D1_LOW","Bilirubin_D1_HIGH",
"MAX_KDIGO_ICU_D0toD3","ECMO_ICUD0toD3","Hours_inICUD0toD3", "Temperature_D1_LOW", "Temperature_D1_HIGH")
#Outdir for mortality
outdir1 <- paste0(out_dir,"mortality/SelectedClinicalFeature2/")
#Outcome column name
outcome_colname <- "Death_inHOSP"
#1.Get model data
model_data <- construct_model_data_func(data_dir,feature_file,outcome_file,outcome_colname)
model_data <- model_data[,c(selected_features,outcome_colname)]
table(model_data$Death_inHOSP)
colnames(model_data)
#2.CV
upsample_flag <- 0
N_sampling <- 10
NFolds <- 10
model_name_list <- c("SVM","RF","LogReg","XGB")
for (m in 1:length(model_name_list)){
model_name <- model_name_list[m]
#CV
cv_res <- cv2_func(model_data,outcome_colname,model_name,upsample_flag,N_sampling,NFolds,svmkernel = "svmLinear2")
final_pred <- cv_res[[1]]
write.csv(final_pred, paste0(outdir1,"Prediction_", model_name, ".csv"),row.names = F)
#compute avg performance
final_importance_matrix <- cv_res[[2]]
feature_indexes<- which(colnames(model_data) != outcome_colname)
features <- colnames(model_data)[feature_indexes]
avg_importance_matrix <- compute_avg_importance(final_importance_matrix,features,model_name)
write.csv(avg_importance_matrix, paste0(outdir1,"Importance_AVG_", model_name, ".csv"),row.names = F)
#Compute perforamnce for each fold with each sampling
eachfold_eachSample_perf_tb <- compute_performance_TrainCV_func(N_sampling,NFolds,final_pred)
write.csv(eachfold_eachSample_perf_tb, paste0(outdir1,"Performance_PerFoldPerSample_", model_name, ".csv"),row.names = F)
#get CI and mean perforamnce
CI_perf_tb <- perf_Mean_CI_func(eachfold_eachSample_perf_tb[,3:14])
write.csv(CI_perf_tb, paste0(outdir1,"Performance_AVG_CI_", model_name, ".csv"),row.names = T)
}
#######################################################################################
######                MAKE with drop50 Prediction   4                      ############
#feature file: Selected Features2
#Outcome file: All_outcome.csv
#######################################################################################
#1.All_Feature_imputed_normed.csv
feature_file <- c("All_Feature_imputed_normed.csv")
selected_features2 <- c("LAST_KDIGO_ICU_D0toD3","UrineOutput_D0toD3","MAX_KDIGO_ICU_D0toD3","Bilirubin_D1_HIGH",
"AGE","BUN_D0toD3_HIGH","Hemoglobin_D1_LOW","Platelets_D1_LOW","FI02_D1_HIGH",
"Vasopressor_ICUD0toD3","HR_D1_HIGH","PH_D1_LOW",
"Hours_inICUD0toD3", "Temperature_D1_LOW", "Temperature_D1_HIGH")
#Outdir for mortality
outdir1 <- paste0(out_dir,"make120_drop50/SelectedClinicalFeature2/")
#Outcome column name
outcome_colname <- "MAKE_HOSP120_Drop50"
#1.Get model data
model_data <- construct_model_data_func(data_dir,feature_file,outcome_file,outcome_colname)
model_data <- model_data[,c(selected_features2,outcome_colname)]
table(model_data$MAKE_HOSP120_Drop50)
colnames(model_data)
#2.CV
upsample_flag <- 0
N_sampling <- 10
NFolds <- 10
model_name_list <- c("SVM","RF","LogReg","XGB")
for (m in 1:length(model_name_list)){
model_name <- model_name_list[m]
#CV
cv_res <- cv2_func(model_data,outcome_colname,model_name,upsample_flag,N_sampling,NFolds,svmkernel = "svmLinear2") #svmPoly, svmLinear,svmLinear2
final_pred <- cv_res[[1]]
write.csv(final_pred, paste0(outdir1,"Prediction_", model_name, ".csv"),row.names = F)
#compute avg performance
final_importance_matrix <- cv_res[[2]]
feature_indexes<- which(colnames(model_data) != outcome_colname)
features <- colnames(model_data)[feature_indexes]
avg_importance_matrix <- compute_avg_importance(final_importance_matrix,features,model_name)
write.csv(avg_importance_matrix, paste0(outdir1,"Importance_AVG_", model_name, ".csv"),row.names = F)
#Compute perforamnce for each fold with each sampling
eachfold_eachSample_perf_tb <- compute_performance_TrainCV_func(N_sampling,NFolds,final_pred)
write.csv(eachfold_eachSample_perf_tb, paste0(outdir1,"Performance_PerFoldPerSample_", model_name, ".csv"),row.names = F)
#get CI and mean perforamnce
CI_perf_tb <- perf_Mean_CI_func(eachfold_eachSample_perf_tb[,3:14])
write.csv(CI_perf_tb, paste0(outdir1,"Performance_AVG_CI_", model_name, ".csv"),row.names = T)
}
#1.All_Feature_imputed_normed.csv
feature_file <- c("All_Feature_imputed_normed.csv")
selected_features2 <- c("LAST_KDIGO_ICU_D0toD3","UrineOutput_D0toD3","MAX_KDIGO_ICU_D0toD3","Bilirubin_D1_HIGH",
"AGE","BUN_D0toD3_HIGH","Hemoglobin_D1_LOW","Platelets_D1_LOW","FI02_D1_HIGH",
"Vasopressor_ICUD0toD3","HR_D1_HIGH","PH_D1_LOW",
"Hours_inICUD0toD3", "Temperature_D1_LOW", "Temperature_D1_HIGH","Peak_SCr_inICU_D0_D3")
#Outdir for mortality
outdir1 <- paste0(out_dir,"make120_drop50/SelectedClinicalFeature2/")
#Outcome column name
outcome_colname <- "MAKE_HOSP120_Drop50"
#1.Get model data
model_data <- construct_model_data_func(data_dir,feature_file,outcome_file,outcome_colname)
model_data <- model_data[,c(selected_features2,outcome_colname)]
table(model_data$MAKE_HOSP120_Drop50)
colnames(model_data)
#2.CV
upsample_flag <- 0
N_sampling <- 10
NFolds <- 10
model_name_list <- c("SVM","RF","LogReg","XGB")
for (m in 1:length(model_name_list)){
model_name <- model_name_list[m]
#CV
cv_res <- cv2_func(model_data,outcome_colname,model_name,upsample_flag,N_sampling,NFolds,svmkernel = "svmLinear2") #svmPoly, svmLinear,svmLinear2
final_pred <- cv_res[[1]]
write.csv(final_pred, paste0(outdir1,"Prediction_", model_name, ".csv"),row.names = F)
#compute avg performance
final_importance_matrix <- cv_res[[2]]
feature_indexes<- which(colnames(model_data) != outcome_colname)
features <- colnames(model_data)[feature_indexes]
avg_importance_matrix <- compute_avg_importance(final_importance_matrix,features,model_name)
write.csv(avg_importance_matrix, paste0(outdir1,"Importance_AVG_", model_name, ".csv"),row.names = F)
#Compute perforamnce for each fold with each sampling
eachfold_eachSample_perf_tb <- compute_performance_TrainCV_func(N_sampling,NFolds,final_pred)
write.csv(eachfold_eachSample_perf_tb, paste0(outdir1,"Performance_PerFoldPerSample_", model_name, ".csv"),row.names = F)
#get CI and mean perforamnce
CI_perf_tb <- perf_Mean_CI_func(eachfold_eachSample_perf_tb[,3:14])
write.csv(CI_perf_tb, paste0(outdir1,"Performance_AVG_CI_", model_name, ".csv"),row.names = T)
}
feature_file <- c("All_Feature_imputed_normed.csv")
selected_features2 <- c("LAST_KDIGO_ICU_D0toD3","UrineOutput_D0toD3","MAX_KDIGO_ICU_D0toD3","Bilirubin_D1_HIGH",
"AGE","BUN_D0toD3_HIGH","Hemoglobin_D1_LOW","Platelets_D1_LOW","FI02_D1_HIGH",
"Vasopressor_ICUD0toD3","HR_D1_HIGH","PH_D1_LOW",
"Hours_inICUD0toD3", "Temperature_D1_LOW", "Temperature_D1_HIGH")
#Outdir for mortality
outdir1 <- paste0(out_dir,"make120_drop50/SelectedClinicalFeature2/")
#Outcome column name
outcome_colname <- "MAKE_HOSP120_Drop50"
#1.Get model data
model_data <- construct_model_data_func(data_dir,feature_file,outcome_file,outcome_colname)
model_data <- model_data[,c(selected_features2,outcome_colname)]
table(model_data$MAKE_HOSP120_Drop50)
colnames(model_data)
#2.CV
upsample_flag <- 0
N_sampling <- 10
NFolds <- 10
model_name_list <- c("SVM","RF","LogReg","XGB")
for (m in 1:length(model_name_list)){
model_name <- model_name_list[m]
#CV
cv_res <- cv2_func(model_data,outcome_colname,model_name,upsample_flag,N_sampling,NFolds,svmkernel = "svmLinear2") #svmPoly, svmLinear,svmLinear2
final_pred <- cv_res[[1]]
write.csv(final_pred, paste0(outdir1,"Prediction_", model_name, ".csv"),row.names = F)
#compute avg performance
final_importance_matrix <- cv_res[[2]]
feature_indexes<- which(colnames(model_data) != outcome_colname)
features <- colnames(model_data)[feature_indexes]
avg_importance_matrix <- compute_avg_importance(final_importance_matrix,features,model_name)
write.csv(avg_importance_matrix, paste0(outdir1,"Importance_AVG_", model_name, ".csv"),row.names = F)
#Compute perforamnce for each fold with each sampling
eachfold_eachSample_perf_tb <- compute_performance_TrainCV_func(N_sampling,NFolds,final_pred)
write.csv(eachfold_eachSample_perf_tb, paste0(outdir1,"Performance_PerFoldPerSample_", model_name, ".csv"),row.names = F)
#get CI and mean perforamnce
CI_perf_tb <- perf_Mean_CI_func(eachfold_eachSample_perf_tb[,3:14])
write.csv(CI_perf_tb, paste0(outdir1,"Performance_AVG_CI_", model_name, ".csv"),row.names = T)
}
#1.All_Feature_imputed_normed.csv
feature_file <- c("All_Feature_imputed_normed.csv")
selected_features2 <- c("LAST_KDIGO_ICU_D0toD3","UrineOutput_D0toD3","MAX_KDIGO_ICU_D0toD3","Bilirubin_D1_HIGH",
"AGE","BUN_D0toD3_HIGH","Hemoglobin_D1_LOW","Platelets_D1_LOW","FI02_D1_HIGH",
"Vasopressor_ICUD0toD3","HR_D1_HIGH","PH_D1_LOW",
"Hours_inICUD0toD3", "Temperature_D1_LOW", "Temperature_D1_HIGH")
#Outdir for mortality
outdir1 <- paste0(out_dir,"make120_drop50/SelectedClinicalFeature2/")
#Outcome column name
outcome_colname <- "MAKE_HOSP120_Drop50"
#1.Get model data
model_data <- construct_model_data_func(data_dir,feature_file,outcome_file,outcome_colname)
model_data <- model_data[,c(selected_features2,outcome_colname)]
table(model_data$MAKE_HOSP120_Drop50)
colnames(model_data)
#2.CV
upsample_flag <- 0
N_sampling <- 10
NFolds <- 10
model_name_list <- c("SVM","RF","LogReg","XGB")
for (m in 1:length(model_name_list)){
model_name <- model_name_list[m]
#CV
cv_res <- cv2_func(model_data,outcome_colname,model_name,upsample_flag,N_sampling,NFolds,svmkernel = "svmLinear2") #svmPoly, svmLinear,svmLinear2
final_pred <- cv_res[[1]]
write.csv(final_pred, paste0(outdir1,"Prediction_", model_name, ".csv"),row.names = F)
#compute avg performance
final_importance_matrix <- cv_res[[2]]
feature_indexes<- which(colnames(model_data) != outcome_colname)
features <- colnames(model_data)[feature_indexes]
avg_importance_matrix <- compute_avg_importance(final_importance_matrix,features,model_name)
write.csv(avg_importance_matrix, paste0(outdir1,"Importance_AVG_", model_name, ".csv"),row.names = F)
#Compute perforamnce for each fold with each sampling
eachfold_eachSample_perf_tb <- compute_performance_TrainCV_func(N_sampling,NFolds,final_pred)
write.csv(eachfold_eachSample_perf_tb, paste0(outdir1,"Performance_PerFoldPerSample_", model_name, ".csv"),row.names = F)
#get CI and mean perforamnce
CI_perf_tb <- perf_Mean_CI_func(eachfold_eachSample_perf_tb[,3:14])
write.csv(CI_perf_tb, paste0(outdir1,"Performance_AVG_CI_", model_name, ".csv"),row.names = T)
}
setwd("~/Desktop/DrChen_Projects/All_AKI_Projects/Other_Project/TAKI_Project/TAKI_Code")
source("TAKI_Ultility.R")
get_allmethods_performance <- function(folder_name,file_names,feature_set_name){
file_dir <- paste0(folder_name,feature_set_name,"/",file_names)
perfs_list <- list(NA)
for (i in 1:length(file_dir)){
curr_file <- file_dir[i]
curr_method_name <- gsub(paste0(folder_name,feature_set_name,"/Performance_AVG_CI_|.csv"),"",curr_file)
curr_perf <- read.csv(curr_file ,stringsAsFactors = F)
colnames(curr_perf) <- c("Metrics",paste0(feature_set_name,"_",curr_method_name,"_Mean_95CI"))
perfs_list[[i]] <- curr_perf
}
perfs <- do.call(cbind,perfs_list)
perfs <- perfs[,-c(3,5,7)] #remove duplicated "metric" col
return(perfs)
}
#######################################################################################
##### 1. Cross Validation Mortality performance
#######################################################################################
perf_dir <- "/Users/lucasliu/Desktop/DrChen_Projects/All_AKI_Projects/Other_Project/TAKI_Project/Intermediate_Results/Prediction_results0708/"
folder_name <- paste0(perf_dir,"CV_performance/mortality/")
method_names <- c("LogReg","RF","SVM","XGB")
perf_file_names <- paste0("Performance_AVG_CI_",method_names,".csv")
prediction_file_names <- paste0("Prediction_",method_names,".csv")
#1. Performances using different feature
SOFA_perfs <- get_allmethods_performance(folder_name,perf_file_names,"SOFA")
APACHE_perfs <- get_allmethods_performance(folder_name,perf_file_names,"APACHE")
SelectedClinicalFeature_perfs <- get_allmethods_performance(folder_name,perf_file_names,"SelectedClinicalFeature")
SelectedClinicalFeature_perfs2 <- get_allmethods_performance(folder_name,perf_file_names,"SelectedClinicalFeature2")
AllClinicalFeature_perfs <- get_allmethods_performance(folder_name,perf_file_names,"AllClinicalFeature")
all_perfs <- cbind(SOFA_perfs,APACHE_perfs,SelectedClinicalFeature_perfs,SelectedClinicalFeature_perfs2,AllClinicalFeature_perfs)
colnames(all_perfs)
all_perfs <- all_perfs[-c(6,11,16,21)]
#2.For each featuresets and each method, compare with baseline AUC diff
AUC_diff <- as.data.frame(matrix(NA, nrow = 2, ncol = ncol(all_perfs)))
colnames(AUC_diff) <- colnames(all_perfs)
AUC_diff$Metrics[1] <- "AUC_Diff"
AUC_diff$Metrics[2] <- "AUC_Diff_Pvalue"
baseline_sets <- "SOFA"
for (i in 2:ncol(AUC_diff)){ #for each feature set
curr_col <- colnames(AUC_diff)[i]
curr_comp_feature <- unlist(strsplit(curr_col,split = "_"))[1]
curr_method <- unlist(strsplit(curr_col,split = "_"))[2]
if (curr_comp_feature != baseline_sets){
#baseline AUC
baseline_auc_colidxes <- which(grepl(paste0(baseline_sets,"_",curr_method),colnames(all_perfs))== T)
baseline_auc <-  all_perfs[which(all_perfs$Metrics == "AUC"),baseline_auc_colidxes]
baseline_auc <- as.numeric(unlist(strsplit(baseline_auc,split = "(",fixed = T))[[1]])
tocompare_auc_colidxes <- which(grepl(paste0(curr_comp_feature,"_",curr_method),colnames(all_perfs))== T)
tocompare_auc <-  all_perfs[which(all_perfs$Metrics == "AUC"),tocompare_auc_colidxes]
tocompare_auc <- as.numeric(unlist(strsplit(tocompare_auc,split = "(",fixed = T))[[1]])
AUC_diff[1,i] <- round(tocompare_auc - baseline_auc,2)
baseline_pred_file <- paste0(baseline_sets,"/Prediction_",curr_method,".csv")
tocompare_pred_file <- paste0(curr_comp_feature,"/Prediction_",curr_method,".csv")
p_value <- Test_AUC_diff_func(folder_name,baseline_pred_file,tocompare_pred_file)
if (p_value < 0.001){
p_value <- "< 0.001"
}
AUC_diff[2,i] <- p_value
}else{
AUC_diff[1,i] <- "-"
AUC_diff[2,i] <- "-"
}
}
Final_all_perfs <- rbind(all_perfs,AUC_diff)
reorder_names <- c("AUC" ,"AUC_Diff", "AUC_Diff_Pvalue", "Accuracy" ,"Precision" ,"Sensitivity","Specificity",
"F1",  "PPV" ,"NPV" ,"Calibration_Intercept","Calibration_Slope" ,"Taylor_Calibration_Intercept",
"Taylor_Calibration_Slope")
Final_all_perfs <- Final_all_perfs[match(reorder_names,Final_all_perfs$Metrics),]
write.csv(Final_all_perfs, paste0(folder_name,"Performance_AVG_CI_Altogether.csv"),row.names = F)
#######################################################################################
##### 2.Cross Validation Mortality MAKE drop 50
#######################################################################################
rm() #clear all vairbales
perf_dir <- "/Users/lucasliu/Desktop/DrChen_Projects/All_AKI_Projects/Other_Project/TAKI_Project/Intermediate_Results/Prediction_results0708/"
folder_name <- paste0(perf_dir,"CV_performance/make120_drop50/")
method_names <- c("LogReg","RF","SVM","XGB")
perf_file_names <- paste0("Performance_AVG_CI_",method_names,".csv")
prediction_file_names <- paste0("Prediction_",method_names,".csv")
#1. Performances using different feature
KDIGO_perfs <- get_allmethods_performance(folder_name,perf_file_names,"KDIGO")
SelectedClinicalFeature_perfs <- get_allmethods_performance(folder_name,perf_file_names,"SelectedClinicalFeature")
SelectedClinicalFeature_perfs2 <- get_allmethods_performance(folder_name,perf_file_names,"SelectedClinicalFeature2")
AllClinicalFeature_perfs <- get_allmethods_performance(folder_name,perf_file_names,"AllClinicalFeature")
all_perfs <- cbind(KDIGO_perfs,SelectedClinicalFeature_perfs,SelectedClinicalFeature_perfs2,AllClinicalFeature_perfs)
colnames(all_perfs)
all_perfs <- all_perfs[-c(6,11,16)]
#2.For each featuresets and each method, compare with baseline AUC diff
AUC_diff <- as.data.frame(matrix(NA, nrow = 2, ncol = ncol((all_perfs))))
colnames(AUC_diff) <- colnames(all_perfs)
AUC_diff$Metrics[1] <- "AUC_Diff"
AUC_diff$Metrics[2] <- "AUC_Diff_Pvalue"
baseline_sets <- "KDIGO"
for (i in 2:ncol(AUC_diff)){ #for each feature set
curr_col <- colnames(AUC_diff)[i]
curr_comp_feature <- unlist(strsplit(curr_col,split = "_"))[1]
curr_method <- unlist(strsplit(curr_col,split = "_"))[2]
if (curr_comp_feature != baseline_sets){
#baseline AUC
baseline_auc_colidxes <- which(grepl(paste0(baseline_sets,"_",curr_method),colnames(all_perfs))== T)
baseline_auc <-  all_perfs[which(all_perfs$Metrics == "AUC"),baseline_auc_colidxes]
baseline_auc <- as.numeric(unlist(strsplit(baseline_auc,split = "(",fixed = T))[[1]])
tocompare_auc_colidxes <- which(grepl(paste0(curr_comp_feature,"_",curr_method),colnames(all_perfs))== T)
tocompare_auc <-  all_perfs[which(all_perfs$Metrics == "AUC"),tocompare_auc_colidxes]
tocompare_auc <- as.numeric(unlist(strsplit(tocompare_auc,split = "(",fixed = T))[[1]])
AUC_diff[1,i] <- round(tocompare_auc - baseline_auc,2)
baseline_pred_file <- paste0(baseline_sets,"/Prediction_",curr_method,".csv")
tocompare_pred_file <- paste0(curr_comp_feature,"/Prediction_",curr_method,".csv")
p_value <- Test_AUC_diff_func(folder_name,baseline_pred_file,tocompare_pred_file)
if (p_value < 0.001){
p_value <- "< 0.001"
}
AUC_diff[2,i] <- p_value
}else{
AUC_diff[1,i] <- "-"
AUC_diff[2,i] <- "-"
}
}
Final_all_perfs <- rbind(all_perfs,AUC_diff)
reorder_names <- c("AUC" ,"AUC_Diff", "AUC_Diff_Pvalue", "Accuracy" ,"Precision" ,"Sensitivity","Specificity",
"F1",  "PPV" ,"NPV" ,"Calibration_Intercept","Calibration_Slope" ,"Taylor_Calibration_Intercept",
"Taylor_Calibration_Slope")
Final_all_perfs <- Final_all_perfs[match(reorder_names,Final_all_perfs$Metrics),]
write.csv(Final_all_perfs, paste0(folder_name,"Performance_AVG_CI_Altogether.csv"),row.names = F)
source("TAKI_Ultility.R")
proj_dir  <- "/Users/lucasliu/Desktop/DrChen_Projects/All_AKI_Projects/Other_Project/TAKI_Project/Intermediate_Results/Prediction_results0708/"
##################################################################################################
######                         Mortality                                            ##############
##################################################################################################
#1. UK
UK_mortality_dir <- paste0(proj_dir,"CV_performance/mortality/")
method_name <- "RF"
#1. Load pred table
pred_df <- read.csv(paste0(UK_mortality_dir, "SelectedClinicalFeature2/Prediction_",method_name,".csv"),stringsAsFactors = F)
#2.Compute avg pred risk
risk_mortality_UK <- get_avg_pred_func(pred_df)
#2.Compute avg pred risk
risk_mortality_UK <- get_avg_pred_func(pred_df)
write.csv(risk_mortality_UK,paste0(UK_mortality_dir,"UK_SelectedFeature2_Mortality_AVG_Pred_Risk_",method_name,".csv"))
#3.Count risk category
risk_mortality_UK_count <- count_risk_category(risk_mortality_UK)
source("TAKI_Ultility.R")
proj_dir  <- "/Users/lucasliu/Desktop/DrChen_Projects/All_AKI_Projects/Other_Project/TAKI_Project/Intermediate_Results/Prediction_results0708/"
##################################################################################################
######                         Mortality                                            ##############
##################################################################################################
#1. UK
UK_mortality_dir <- paste0(proj_dir,"CV_performance/mortality/")
method_name <- "RF"
featureset_folder <- "SelectedClinicalFeature2"
#1. Load pred table
pred_df <- read.csv(paste0(UK_mortality_dir, featureset_folder, "/Prediction_",method_name,".csv"),stringsAsFactors = F)
#2.Compute avg pred risk
risk_mortality_UK <- get_avg_pred_func(pred_df)
write.csv(risk_mortality_UK,paste0(UK_mortality_dir,"UK_",featureset_folder,"_Mortality_AVG_Pred_Risk_",method_name,".csv"))
#3.Count risk category
risk_mortality_UK_count <- count_risk_category(risk_mortality_UK)
write.csv(risk_mortality_UK_count,paste0(UK_mortality_dir,"UK_",featureset_folder,"_Mortality_Risk_Catogory_",method_name,".csv"))
##################################################################################################
############## MAKE ##############
##################################################################################################
#1. UK
UK_MAKE_dir <- paste0(proj_dir,"CV_performance/make120_drop50/")
method_name <- "RF"
featureset_folder <- "SelectedClinicalFeature2"
#1. Load pred table
pred_df <- read.csv(paste0(UK_MAKE_dir,featureset_folder,"/Prediction_",method_name,".csv"),stringsAsFactors = F)
#2.Compute avg pred risk
risk_make_UK <- get_avg_pred_func(pred_df)
write.csv(risk_make_UK,paste0(UK_MAKE_dir,"UK_",featureset_folder,"_MAKE_AVG_Pred_Risk_",method_name,".csv"))
#3.Count risk category
risk_make_UK_count <- count_risk_category(risk_make_UK)
write.csv(risk_make_UK_count,paste0(UK_MAKE_dir,"UK_",featureset_folder,"_MAKE_Risk_Catogory_",method_name,".csv"))
source("TAKI_Ultility.R")
proj_dir  <- "/Users/lucasliu/Desktop/DrChen_Projects/All_AKI_Projects/Other_Project/TAKI_Project/Intermediate_Results/Prediction_results0708/"
###############################################################
#1. For mortality, compare models with IDI, NRI
###############################################################
#1. For UK
perf_dir <- paste0(proj_dir,"CV_performance/mortality/")
baseline_model_file  <- "/SOFA/Prediction_RF.csv"
comprison_model_file1 <- "/APACHE/Prediction_RF.csv"
comprison_model_file2 <- "/SelectedClinicalFeature2/Prediction_RF.csv"
reclass_res1 <- compute_IDI_NRI_func(perf_dir,baseline_model_file,comprison_model_file1,cutoff = c(0,0.5,1))
colnames(reclass_res1)[2] <- paste0("APACHEvsSOFA_",colnames(reclass_res1)[2])
reclass_res2 <- compute_IDI_NRI_func(perf_dir,baseline_model_file,comprison_model_file2,cutoff = c(0,0.5,1))
colnames(reclass_res2)[2] <- paste0("SelectedClinicalFeature2vsSOFA_",colnames(reclass_res2)[2])
comb_res <- cbind(reclass_res1,reclass_res2)
View(comb_res)
comb_res <- cbind(reclass_res1,reclass_res2)
write.csv(comb_res,paste0(perf_dir,"UK_SelectedClinicalFeature2_Mortality_ReclassResults_RF.csv"))
###############################################################
#1. For MAKE, compare models with IDI, NRI
###############################################################
#1.UK
perf_dir <- paste0(proj_dir,"CV_performance/make120_drop50/")
baseline_model_file  <- "/KDIGO/Prediction_RF.csv"
comprison_model_file1 <- "/SelectedClinicalFeature2/Prediction_RF.csv"
reclass_res <- compute_IDI_NRI_func(perf_dir,baseline_model_file,comprison_model_file1,cutoff = c(0,0.5,1))
colnames(reclass_res)[2] <- paste0("SelectedClinical2vsKDIGO_",colnames(reclass_res)[2])
write.csv(reclass_res,paste0(perf_dir,"UK_MAKE50_ReclassResults_RF.csv"))
write.csv(reclass_res,paste0(perf_dir,"UK_SelectedClinical2_MAKE50_ReclassResults_RF.csv"))
perf_dir <- paste0(proj_dir,"CV_performance/make120_drop50/")
baseline_model_file  <- "/KDIGO/Prediction_RF.csv"
comprison_model_file1 <- "/SelectedClinicalFeature/Prediction_RF.csv"
reclass_res <- compute_IDI_NRI_func(perf_dir,baseline_model_file,comprison_model_file1,cutoff = c(0,0.5,1))
colnames(reclass_res)[2] <- paste0("SelectedClinicalvsKDIGO_",colnames(reclass_res)[2])
write.csv(reclass_res,paste0(perf_dir,"UK_SelectedClinical1_MAKE50_ReclassResults_RF.csv"))
perf_dir <- paste0(proj_dir,"CV_performance/make120_drop50/")
baseline_model_file  <- "/KDIGO/Prediction_RF.csv"
comprison_model_file1 <- "/SelectedClinicalFeature2/Prediction_RF.csv"
reclass_res <- compute_IDI_NRI_func(perf_dir,baseline_model_file,comprison_model_file1,cutoff = c(0,0.5,1))
colnames(reclass_res)[2] <- paste0("SelectedClinical2vsKDIGO_",colnames(reclass_res)[2])
write.csv(reclass_res,paste0(perf_dir,"UK_SelectedClinical2_MAKE_ReclassResults_RF.csv"))
